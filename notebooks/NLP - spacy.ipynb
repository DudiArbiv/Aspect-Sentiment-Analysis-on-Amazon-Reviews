{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/apple/Documents/gatech/dva_6242/project/notebooks/data/raw/amazon_reviews_us_Electronics_v1_00.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-827c23964a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maspect_extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maspect_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maspect_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/gatech/dva_6242/project/src/models/aspect_extraction.py\u001b[0m in \u001b[0;36maspect_extraction\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/data/raw/amazon_reviews_us_Electronics_v1_00.tsv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfetch_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0maspect_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_aspects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/gatech/dva_6242/project/src/models/aspect_extraction.py\u001b[0m in \u001b[0;36mfetch_reviews\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/apple/Documents/gatech/dva_6242/project/notebooks/data/raw/amazon_reviews_us_Electronics_v1_00.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "# from src.models import aspect_extraction\n",
    "\n",
    "# aspect_extraction.aspect_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this is worst, i test it when i got it since it arrived very very late..i charge it up within the 4 hours of charge time and tested it, it ok and then the next day it just malfunction/stop working till now..so this is just a garbage"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999999 999999\n",
      "this False\n",
      "worst False\n",
      "this 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "is True\n",
      ", False\n",
      "i True\n",
      "it False\n",
      "got False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "when True\n",
      "i True\n",
      "it False\n",
      "arrived False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "since False\n",
      "it False\n",
      "late False\n",
      "it 999999\n",
      "999999 999999\n",
      "very True\n",
      "999999 999999\n",
      "very True\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "test False\n",
      ".. False\n",
      "i True\n",
      "it False\n",
      "up True\n",
      "within False\n",
      "and True\n",
      "tested False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "hours False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "the True\n",
      "4 False\n",
      "of True\n",
      "999999 999999\n",
      "time False\n",
      "999999 999999\n",
      "999999 999999\n",
      "charge False\n",
      "999999 999999\n",
      "999999 999999\n",
      "it False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      ", False\n",
      "it False\n",
      "it 999999\n",
      "999999 999999\n",
      "day False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "the True\n",
      "next False\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "it False\n",
      "just True\n",
      "it 999999\n",
      "999999 999999\n",
      "and True\n",
      "then True\n",
      "malfunction False\n",
      "/ False\n",
      "working False\n",
      ".. False\n",
      "999999 999999\n",
      "till False\n",
      "999999 999999\n",
      "now True\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "999999 999999\n",
      "so True\n",
      "this False\n",
      "just True\n",
      "garbage False\n",
      "garbage False\n",
      "this garbage\n",
      "999999 999999\n",
      "999999 999999\n",
      "a True\n",
      "999999 999999\n"
     ]
    }
   ],
   "source": [
    "rule7_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        print(child.text, child.is_stop)\n",
    "\n",
    "\n",
    "        if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "            A = child.text\n",
    "\n",
    "\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if((child.dep_ == \"attr\") and not child.is_stop):\n",
    "            print(child.text, child.is_stop)\n",
    "            M = child.text\n",
    "            #check_spelling(child.text)\n",
    "    print(A,M)\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "\n",
    "        rule7_pairs.append((A, M))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'garbage')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule7_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get this from some place else. This is just for dummy usage\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_lg\") \n",
    "for w in stopwords:\n",
    "        nlp.vocab[w].is_stop = True\n",
    "nlp.vocab['this'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9076: expected 15 fields, saw 22\\nSkipping line 19256: expected 15 fields, saw 22\\nSkipping line 24313: expected 15 fields, saw 22\\nSkipping line 47211: expected 15 fields, saw 22\\nSkipping line 54295: expected 15 fields, saw 22\\nSkipping line 56641: expected 15 fields, saw 22\\nSkipping line 63067: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 93796: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 132806: expected 15 fields, saw 22\\nSkipping line 164631: expected 15 fields, saw 22\\nSkipping line 167019: expected 15 fields, saw 22\\nSkipping line 167212: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 198103: expected 15 fields, saw 22\\nSkipping line 199191: expected 15 fields, saw 22\\nSkipping line 202841: expected 15 fields, saw 22\\nSkipping line 218228: expected 15 fields, saw 22\\nSkipping line 235900: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 277761: expected 15 fields, saw 22\\nSkipping line 304582: expected 15 fields, saw 22\\nSkipping line 312029: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 343692: expected 15 fields, saw 22\\nSkipping line 352291: expected 15 fields, saw 22\\nSkipping line 363414: expected 15 fields, saw 22\\nSkipping line 378087: expected 15 fields, saw 22\\nSkipping line 378720: expected 15 fields, saw 22\\nSkipping line 378760: expected 15 fields, saw 22\\nSkipping line 379336: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 402682: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 466560: expected 15 fields, saw 22\\nSkipping line 486823: expected 15 fields, saw 22\\nSkipping line 489036: expected 15 fields, saw 22\\nSkipping line 496148: expected 15 fields, saw 22\\nSkipping line 522330: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 552961: expected 15 fields, saw 22\\nSkipping line 577388: expected 15 fields, saw 22\\nSkipping line 582182: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 590653: expected 15 fields, saw 22\\nSkipping line 608846: expected 15 fields, saw 22\\nSkipping line 615442: expected 15 fields, saw 22\\nSkipping line 645607: expected 15 fields, saw 22\\nSkipping line 654323: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 714935: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 749608: expected 15 fields, saw 22\\nSkipping line 753868: expected 15 fields, saw 22\\nSkipping line 762504: expected 15 fields, saw 22\\nSkipping line 771706: expected 15 fields, saw 22\\nSkipping line 773376: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 792407: expected 15 fields, saw 22\\nSkipping line 793933: expected 15 fields, saw 22\\nSkipping line 813269: expected 15 fields, saw 22\\nSkipping line 835491: expected 15 fields, saw 22\\nSkipping line 841176: expected 15 fields, saw 22\\nSkipping line 844604: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 857952: expected 15 fields, saw 22\\nSkipping line 859568: expected 15 fields, saw 22\\nSkipping line 860789: expected 15 fields, saw 22\\nSkipping line 863093: expected 15 fields, saw 22\\nSkipping line 881608: expected 15 fields, saw 22\\nSkipping line 891157: expected 15 fields, saw 22\\nSkipping line 893799: expected 15 fields, saw 22\\nSkipping line 906438: expected 15 fields, saw 22\\nSkipping line 914856: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 940736: expected 15 fields, saw 22\\nSkipping line 965818: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 993840: expected 15 fields, saw 22\\nSkipping line 1019036: expected 15 fields, saw 22\\nSkipping line 1019205: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1058122: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1144887: expected 15 fields, saw 22\\nSkipping line 1147255: expected 15 fields, saw 22\\nSkipping line 1164497: expected 15 fields, saw 22\\nSkipping line 1166930: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1218319: expected 15 fields, saw 22\\nSkipping line 1232868: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1307335: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1621422: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1857720: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1935753: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1988449: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = os.path.abspath(os.path.join('..')) # base path of project\n",
    "\n",
    "file_path = BASE_PATH + '/data/raw/amazon_reviews_us_Electronics_v1_00.tsv'\n",
    "\n",
    "raw_data = pd.read_table(file_path,error_bad_lines=False)\n",
    "#raw_data\n",
    "#review_body = raw_data['review_body']\n",
    "#reviews = raw_data[['review_id', 'review_body']]\n",
    "\n",
    "raw_data['review_date'] = pd.to_datetime(raw_data['review_date'])\n",
    "# raw_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(string):\n",
    "    print(\"******Cleaning Started*****\")\n",
    "\n",
    "    \n",
    "    string = string.str.replace(\"<br />\", \" \")\n",
    "    string = string.str.replace(\"\\[?\\[.+?\\]?\\]\", \" \")\n",
    "    string= string.str.replace(\"\\/{3,}\", \" \")\n",
    "    string = string.str.replace(\"\\&\\#.+\\&\\#\\d+?;\", \" \")\n",
    "    string = string.str.replace(\"\\d+\\&\\#\\d+?;\", \" \")\n",
    "    string = string.str.replace(\"\\&\\#\\d+?;\", \" \")\n",
    "\n",
    "    #facial expressions\n",
    "    string = string.str.replace(\"\\:\\|\", \"\")\n",
    "    string= string.str.replace(\"\\:\\)\", \"\")\n",
    "    string = string.str.replace(\"\\:\\(\", \"\")\n",
    "    string= string.str.replace(\"\\:\\/\", \"\")\n",
    "\n",
    "    #replace multiple spaces with single space\n",
    "    string= string.str.replace(\"\\s{2,}\", \" \")\n",
    "\n",
    "    string = string.str.lower()\n",
    "\n",
    "    print(\"******Cleaning Ended*****\")\n",
    "\n",
    "\n",
    "    return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Cleaning Started*****\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-66fb3593aa1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-78cbaaa82212>\u001b[0m in \u001b[0;36mclean_data\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<br />\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\[?\\[.+?\\]?\\]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\/{3,}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "clean_data(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162    this is worst, I test it when i got it since it arrived very very late..I charge it up within the 4 hours of charge time and tested it, it ok and then the next day it just malfunction/stop working till now..so this is just a garbage..\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "dummy = raw_data.loc[raw_data['review_id'] == \"R3UI4N17LU4D7O\"]['review_body']\n",
    "\n",
    "print(str(dummy))\n",
    "\n",
    "# doc=nlp(dummy) \n",
    "# for token in doc:\n",
    "#     print(token.text,token.tag_, token.dep_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspects(x):\n",
    "    doc=nlp(x) \n",
    "    doc=[i.text for i in doc if i.text not in stop_words and i.pos_==\"NOUN\"] ## Remove common words and retain only nouns\n",
    "    doc=list(map(lambda i: i.lower(),doc)) ## Normalize text to lower case\n",
    "    doc=pd.Series(doc)\n",
    "    doc=doc.value_counts().head().index.tolist() ## Get 5 most frequent nouns\n",
    "    return doc\n",
    "\n",
    "aspects = []\n",
    "\n",
    "for review in review_body :\n",
    "    aspects.append(get_aspects(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = \"this is worst, i test it when i got it since it arrived very very late..i charge it up within the 4 hours of charge time and tested it, it ok and then the next day it just malfunction/stop working till now..so this is just a garbage\"\n",
    "doc=nlp(dummy) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the DT det DET True\n",
      "story NN nsubj NOUN False\n",
      "got VBD ROOT VERB False\n",
      "stale JJ acomp ADJ False\n",
      ". . punct PUNCT False\n",
      "its PRP$ poss ADJ True\n",
      "the DT det DET True\n",
      "worst JJS ROOT ADJ False\n"
     ]
    }
   ],
   "source": [
    "#dummy = \"The sound quality of the speakers are wonderful. However, the packaging could have been better. Photos under low lighting is poor - both front and back cameras\"\n",
    "dummy = \"The story got stale. Its the worst\"\n",
    "dummy = str.lower(dummy)\n",
    "doc=nlp(dummy) \n",
    "for token in doc:\n",
    "    print(token.text,token.tag_, token.dep_, token.pos_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the DT det DET True\n",
      "flat JJ amod ADJ False\n",
      "cord NN ROOT NOUN False\n",
      "i PRP nsubj PRON True\n",
      "used VBD relcl VERB False\n",
      "twice RB advmod ADV False\n",
      "and CC cc CCONJ True\n",
      "it PRP nsubj PRON True\n",
      "already RB advmod ADV False\n",
      "quit VBD conj VERB False\n",
      "working VBG xcomp VERB False\n",
      ". . punct PUNCT False\n",
      "    SPACE False\n",
      "i PRP nsubj PRON True\n",
      "have VBP ROOT VERB True\n",
      "a DT det DET True\n",
      "cord NN dobj NOUN False\n",
      "that WDT dobj ADJ True\n",
      "i PRP nsubj PRON True\n",
      "paid VBD relcl VERB False\n",
      "about RB advmod ADV True\n",
      "10 CD nummod NUM False\n",
      "bucks NNS dobj NOUN False\n",
      "for IN prep ADP True\n",
      "at IN prep ADP True\n",
      "a DT det DET True\n",
      "gas NN compound NOUN False\n",
      "station NN pobj NOUN False\n",
      "and CC cc CCONJ True\n",
      "it PRP nsubj PRON True\n",
      "has VBZ aux VERB True\n",
      "lasted VBN conj VERB False\n",
      "5 CD nummod NUM False\n",
      "+ SYM cc SYM False\n",
      "years NNS npadvmod NOUN False\n",
      "and CC cc CCONJ True\n",
      "this DT det DET True\n",
      "thing NN nsubj NOUN False\n",
      "does VBZ aux VERB True\n",
      "n't RB neg ADV False\n",
      "last VB conj VERB False\n",
      "2 CD nummod NUM False\n",
      "hours.oh NN dobj NOUN False\n",
      "and CC cc CCONJ True\n",
      "wait VB conj VERB False\n",
      "now RB advmod ADV True\n",
      "i PRP nsubj PRON True\n",
      "ca MD aux VERB False\n",
      "n't RB neg ADV False\n",
      "return VB conj VERB False\n",
      "it PRP dobj PRON True\n",
      "because IN mark ADP True\n",
      "its PRP$ nsubj ADJ True\n",
      "been VBN advcl VERB True\n",
      "30 CD nummod NUM False\n",
      "days NNS attr NOUN False\n",
      ". . punct PUNCT False\n",
      "    SPACE False\n",
      "do VBP ROOT VERB True\n",
      "yourself PRP dative PRON True\n",
      "a DT det DET True\n",
      "favor NN dobj NOUN False\n",
      "and CC cc CCONJ True\n",
      "buy VB conj VERB False\n",
      "something NN dobj NOUN False\n",
      "else RB advmod ADV False\n",
      "from IN prep ADP True\n",
      "someone NN pobj NOUN False\n",
      "else RB advmod ADV False\n",
      ". . punct PUNCT False\n"
     ]
    }
   ],
   "source": [
    "#dummy = \"The sound quality of the speakers are wonderful. However, the packaging could have been better. Photos under low lighting is poor - both front and back cameras\"\n",
    "dummy =  \"The flat cord I used twice and it already quit working.  I have a cord that I paid about 10 bucks for at a gas station and it has lasted 5+ years and this thing doesn't last 2 hours.oh and wait now I can't return it because its been 30 days.  Do yourself a favor and buy something else from someone else.\"\n",
    "dummy = str.lower(dummy)\n",
    "doc=nlp(dummy) \n",
    "for token in doc:\n",
    "    print(token.text,token.tag_, token.dep_, token.pos_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'spacy' has no attribute 'describe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3ec9237b5f6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'spacy' has no attribute 'describe'"
     ]
    }
   ],
   "source": [
    "spacy.describe(\"attr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this is worst, i test it when i got it since it arrived very very late..i charge it up within the 4 hours of charge time and tested it, it ok and then the next day it just malfunction/stop working till now..so this is just a garbage"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule2_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "            A = child.text\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if((child.dep_ == \"dobj\" and child.pos_ == \"ADJ\")and not child.is_stop):\n",
    "            M = child.text\n",
    "            #check_spelling(child.text)\n",
    "\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule2_pairs.append((A, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule2_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule4_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if((child.dep_ == \"nsubjpass\" or child.dep_ == \"nsubj\") and not child.is_stop):\n",
    "            A = child.text\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if(child.dep_ == \"advmod\" and not child.is_stop):\n",
    "            M_children = \n",
    "            M = child.text\n",
    "            #check_spelling(child.text)\n",
    "\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule4_pairs.append((A, M,sid.polarity_scores(M)['compound'])) # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule1_pairs = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"amod\" and not token.is_stop:\n",
    "        #check_spelling(token.text)\n",
    "        rule1_pairs.append((token.head.text, token.text))\n",
    "        #return row['height'] * row['width']\n",
    "\n",
    "\n",
    "## SECOND RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "#Direct Object - A is a child of something with relationship of nsubj, while\n",
    "# M is a child of the same something with relationship of dobj\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule2_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "            A = child.text\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if(child.dep_ == \"dobj\" and not child.is_stop):\n",
    "            M = child.text\n",
    "            #check_spelling(child.text)\n",
    "\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule2_pairs.append((A, M,))\n",
    "\n",
    "\n",
    "## THIRD RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "#Adjectival Complement - A is a child of something with relationship of nsubj, while\n",
    "# M is a child of the same something with relationship of acomp\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule3_pairs = []\n",
    "\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "            A = child.text\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if(child.dep_ == \"acomp\" and not child.is_stop):\n",
    "            M = child.text\n",
    "            #check_spelling(child.text)\n",
    "\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule3_pairs.append((A, M))\n",
    "\n",
    "## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while\n",
    "# M is a child of the same something with relationship of advmod\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule4_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubjpass\" and not child.is_stop):\n",
    "            A = child.text\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if(child.dep_ == \"advmod\" and not child.is_stop):\n",
    "            M = child.text\n",
    "            #check_spelling(child.text)\n",
    "\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule4_pairs.append((A, M)) # )\n",
    "\n",
    "\n",
    "## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Complement of a copular verb - A is a child of M with relationship of nsubj, while\n",
    "# M has a child with relationship of cop\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule5_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    buf_var = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "            A = child.text\n",
    "            # check_spelling(child.text)\n",
    "\n",
    "        if(child.dep_ == \"cop\" and not child.is_stop):\n",
    "            buf_var = child.text\n",
    "            #check_spelling(child.text)\n",
    "\n",
    "    if(A != \"999999\" and buf_var != \"999999\"):\n",
    "        rule5_pairs.append((A, token.text))\n",
    "\n",
    "aspects = []\n",
    "\n",
    "aspects = rule1_pairs + rule2_pairs + rule3_pairs +rule4_pairs +rule5_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cord', 'flat'), ('thing', 'hours.oh')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sound quality  *** quality  *** nsubj  *** are\n",
      "the speakers  *** speakers  *** pobj  *** of\n",
      "the packaging  *** packaging  *** nsubj  *** been\n",
      "Photos  *** Photos  *** nsubj  *** is\n",
      "low lighting  *** lighting  *** pobj  *** under\n",
      "poor - both front and back cameras  *** cameras  *** attr  *** is\n"
     ]
    }
   ],
   "source": [
    "#noun chunks\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text,\" ***\", chunk.root.text, \" ***\",chunk.root.dep_,\" ***\", chunk.root.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **** det **** quality **** False NOUN []\n",
      "sound **** amod **** quality **** False NOUN []\n",
      "quality **** nsubj **** are **** False VERB [The, sound, of]\n",
      "of **** prep **** quality **** False NOUN [speakers]\n",
      "the **** det **** speakers **** False NOUN []\n",
      "speakers **** pobj **** of **** False ADP [the]\n",
      "are **** ROOT **** are **** False VERB [quality, wonderful, .]\n",
      "wonderful **** acomp **** are **** False VERB []\n",
      ". **** punct **** are **** False VERB []\n",
      "However **** advmod **** been **** False VERB []\n",
      ", **** punct **** been **** False VERB []\n",
      "the **** det **** packaging **** False NOUN []\n",
      "packaging **** nsubj **** been **** False VERB [the]\n",
      "could **** aux **** been **** False VERB []\n",
      "have **** aux **** been **** False VERB []\n",
      "been **** ROOT **** been **** False VERB [However, ,, packaging, could, have, better, .]\n",
      "better **** acomp **** been **** False VERB []\n",
      ". **** punct **** been **** False VERB []\n",
      "Photos **** nsubj **** is **** False VERB [under]\n",
      "under **** prep **** Photos **** False NOUN [lighting]\n",
      "low **** amod **** lighting **** False NOUN []\n",
      "lighting **** pobj **** under **** False ADP [low]\n",
      "is **** ROOT **** is **** False VERB [Photos, cameras]\n",
      "poor **** amod **** front **** False NOUN [-]\n",
      "- **** punct **** poor **** False ADJ []\n",
      "both **** preconj **** front **** False NOUN []\n",
      "front **** amod **** cameras **** False NOUN [poor, both, and, back]\n",
      "and **** cc **** front **** False NOUN []\n",
      "back **** conj **** front **** False NOUN []\n",
      "cameras **** attr **** is **** False VERB [front]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,\"****\" ,token.dep_, \"****\" ,token.head.text, \"****\" ,token.is_stop,token.head.pos_,\n",
    "          [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Nov/2018 20:16:02] \"GET / HTTP/1.1\" 200 35934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this if you want to visualise dependancy tree\n",
    "spacy.displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Bass, lacking)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Zero RULE \n",
    "## Noun - Adjective pairs\n",
    "\n",
    "## Very basic rule. Should be least weightage\n",
    "\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','PROPN'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'ADJ':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'sound'),\n",
       " ('lighting', 'low'),\n",
       " ('front', 'poor'),\n",
       " ('cameras', 'front')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIRST RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "## RULE = M is child of A with a relationshio of amod\n",
    "\n",
    "rule1_pairs = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"amod\":\n",
    "        rule1_pairs.append((token.head.text, token.text))\n",
    "\n",
    "rule1_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SECOND RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Direct Object - A is a child of something with relationship of nsubj, while \n",
    "# M is a child of the same something with relationship of dobj\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule2_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "        if(child.dep_ == \"dobj\"):\n",
    "            M = child.text\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule2_pairs.append((A, M))   \n",
    "    \n",
    "         \n",
    "            \n",
    "        \n",
    "        \n",
    "rule2_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'wonderful'), ('packaging', 'better'), ('Photos', 'better')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## THIRD RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adjectival Complement - A is a child of something with relationship of nsubj, while \n",
    "# M is a child of the same something with relationship of acomp\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule3_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    B = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"acomp\"):\n",
    "            M = child.text\n",
    "        \n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule3_pairs.append((A, M)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule3_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while \n",
    "# M is a child of the same something with relationship of advmod\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule4_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubjpass\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"advmod\"):\n",
    "            M = child.text\n",
    "        \n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule4_pairs.append((A, M)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule4_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Complement of a copular verb - A is a child of M with relationship of nsubj, while \n",
    "# M has a child with relationship of cop\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule5_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    buf_var = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"cop\"):\n",
    "            buf_var = child.text\n",
    "        \n",
    "    if(A != \"999999\" or buf_var != \"999999\"):\n",
    "        rule3_pairs.append((A, token.text)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule5_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'wonderful'), ('packaging', 'better'), ('Photos', 'better')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule3_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aspects = []\n",
    "aspects = rule1_pairs + rule2_pairs + rule3_pairs + rule4_pairs + rule5_pairs \n",
    "aspects\n",
    "\n",
    "review_id = \"guhjsus23\"\n",
    "\n",
    "{\"review_id\" : review_id, \"aspects\" : aspects }\n",
    "aspects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_extraction(row,nlp):\n",
    "    review_body = row['review_body']\n",
    "    review_id = row['review_id']\n",
    "\n",
    "    doc=nlp(review_body)\n",
    "\n",
    "\n",
    "    ## FIRST RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## RULE = M is child of A with a relationshio of amod\n",
    "    rule1_pairs = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"amod\":\n",
    "            rule1_pairs.append((token.head.text, token.text))\n",
    "            #return row['height'] * row['width']\n",
    "\n",
    "\n",
    "    ## SECOND RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    #Direct Object - A is a child of something with relationship of nsubj, while\n",
    "    # M is a child of the same something with relationship of dobj\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule2_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\"):\n",
    "                A = child.text\n",
    "            if(child.dep_ == \"dobj\"):\n",
    "                M = child.text\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule2_pairs.append((A, M))\n",
    "\n",
    "\n",
    "    ## THIRD RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    #Adjectival Complement - A is a child of something with relationship of nsubj, while\n",
    "    # M is a child of the same something with relationship of acomp\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule3_pairs = []\n",
    "\n",
    "    for token in doc:\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\"):\n",
    "                A = child.text\n",
    "\n",
    "            if(child.dep_ == \"acomp\"):\n",
    "                M = child.text\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule3_pairs.append((A, M))\n",
    "\n",
    "    ## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "    #Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while\n",
    "    # M is a child of the same something with relationship of advmod\n",
    "\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule4_pairs = []\n",
    "    for token in doc:\n",
    "\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubjpass\"):\n",
    "                A = child.text\n",
    "\n",
    "            if(child.dep_ == \"advmod\"):\n",
    "                M = child.text\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule4_pairs.append((A, M))\n",
    "\n",
    "\n",
    "    ## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "    #Complement of a copular verb - A is a child of M with relationship of nsubj, while\n",
    "    # M has a child with relationship of cop\n",
    "\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule5_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        buf_var = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\"):\n",
    "                A = child.text\n",
    "\n",
    "            if(child.dep_ == \"cop\"):\n",
    "                buf_var = child.text\n",
    "\n",
    "        if(A != \"999999\" and buf_var != \"999999\"):\n",
    "            rule3_pairs.append((A, token.text))\n",
    "\n",
    "    aspects = []\n",
    "    aspects = rule1_pairs + rule2_pairs + rule3_pairs +rule4_pairs +rule5_pairs\n",
    "    dic = {\"review_id\" : review_id , \"aspect_pairs\" : aspects}\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'R372S58V6D11AT', 'aspect_pairs': [('Bass', 'lacking')]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_lg\")\n",
    "reviews.apply(lambda row: apply_extraction(row,nlp), axis=1)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[[VIDEOID:ca7421903fd1ad5c64ae1dc42a160649]] Earbuds have always been an issue for me. Mine is one of those stereotypical stories -- I can\\'t find a pair that fits my ears well. I\\'ve tried so many types of earbuds and most of them give my ear canals some sort of fatigue. It\\'s not that they sound bad, just that keeping them in my ears for more than 10 minutes is painful. The only ones I could tolerate were the Apple EarPods, and I have a love/hate relationship with them. Sure, they sit nicely in my ears, but them being fully open means I lose my music to the crickets of night and pelicans of day. Well, no more! I found the Flare R2A in-ear monitors, and seems my fear of earbuds is over.<br /><br />Disclaimer: This product was provided at a discounted price in exchange for an honest review.<br /><br />The R2s began their life on Kickstarter with a campaign that raised over $170,000. That\\'s quite a lot for IEMs, which are a rather niche market. Flare is a British company that strives for excellence in sound, and hopes that the world can join them in this pursuit. Before the R2s, the company made loudspeakers, so in-ears is a bit of a different industry. I think they did a fine job of things.<br /><br />I listen to a lot of different genres of music, but mostly folk and dream pop lately. To test out the R2s, I listened to hip-hop, jazz, EDM, instrumental guitar and piano, rock, classical, and of course the aforementioned folk. They performed consistently well in every genre. They also look great.<br /><br />First, of course, the sound. These IEMs aren\\'t active noise canceling or anything fancy, which is good because noise canceling often diminishes the sound quality. The R2s are still great for keeping outside noises to a minimum. They use the same plushy foam tips as earplugs, which makes for a comfortable and quiet listening environment. I tried them at work, in the bus, walking down a busy road, and even in a studio while recording. There\\'s absolutely no sound leakage at all, which is great for quiet environments, and none of the quality seems to be lost when the environment is noisy.<br /><br />People sometimes rant about flat response and how it\\'s better than everything else. Those people might be troubled by the R2s. They\\'re warmer than most earbuds, but don\\'t have muddy bass. The main issue with earbuds is always treble: there\\'s way too much of it everywhere. Then Skullcandy wanted to have fun so they started adding a bunch of bass to the mix. Everything above 80Hz seemed to have been lost. The R2s have none of those problems -- highs are crisp, mids cut through well, and the lows of course deliver the much-needed punch, rather than a drone. The responsiveness of everything is very tight.<br /><br />As I said before, everything I listened to with these IEMs sounded wonderful. They revealed details in songs that I didn\\'t know were there, while also being comfortable, affordable, and easy to use. The highs were not overbearing, but pronounced; the high-mids don\\'t clutter the highs at all; the low-mids keep all the bass lines in check; and the lows make sure you remember that the bass drum exists without making you forget about the guitars in the mid-range. That\\'s a great achievement. I really love the way these sound. Everything is balanced. Overall, it\\'s a bit warm, but I would much rather it be warm than sound like tinny old Apple earbuds from the early 2000s, with their mesh and bass-less muddle.<br /><br />On to the design. These things are beautifully minimal, but aren\\'t trying to be artistic, which is nice for a change. The earbuds themselves are black (or whatever color you chose), and the tips and cable match that. There\\'s also a rectangular machined aluminum box that splits the stereo signal for the left and right channels. It doesn\\'t need to be as big as it is, but it does add some pizzazz to things. Lastly, there\\'s the 3.5mm connector, which on mine is black with two gold stripes running through it.<br /><br />I love the design, but there\\'s one ergonomic inconsistency: The aluminum box. It looks cool, and I can see why the designer would have put it there. However, if you want to use these as a versatile pair of IEMs, you may walk with them once in a while, or just move around a bit. The latter is inevitable, and when you do choose to move around you\\'ll hear some strange thudding sounds. That\\'s the box attempting to defy gravity. Every time I hear this I tell myself it\\'s cool to look at, but doesn\\'t need to be so heavy and certainly doesn\\'t add any special functionality. The heaviness, I suppose, adds value to the IEMs. I would just prefer it wasn\\'t here, especially when I\\'m using these to perform.<br /><br />While these are \\\\\\\\\"reference\\\\\\\\\" series -- at least according to the marketing by Flare -- I don\\'t recommend using them for referencing. The R2s don\\'t produce a completely flat sound like Sonys do. They\\'re amazing for listening to, but not necessarily for studio work. I tried mixing a few song using them just for fun, and I noticed that most of my mixes tended to lose the low-mid range on other speakers and headphones simply because the R2s are warm. This characteristic is great when listening to music, but not for mixing/producing it.<br /><br />If you\\'re a musician, you\\'ll find that these are great for monitoring (and thus they are named in-ear monitors). I used them to monitor my vocals and piano while recording an entire song and they worked great. The warmth helps make things less straining on the ears, and there\\'s not so much bass that I get a headache using them after a while. I also used these to monitor my synth and the rest of the band while playing live, and the foam tips isolated the sound very well.<br /><br />It\\'s worth noting that since these are in-ear monitors, there is no microphone. The aluminum block in the middle of the cable just acts as a splitter -- there\\'s no hidden microphone. At first this bugged me, because I would receive a call and forget I couldn\\'t use these headphones to talk. After a while, I just accepted it. There\\'s no reason for IEMs to have a microphone since there\\'s no way for you to use it as a talkback to your band or anything. It also goes against the way that Flare built these, which is to solely focus on recreating sound accurately, not adding more sound. Bottom line: A microphone would have been useful, but there isn\\'t one, and that shouldn\\'t be a deal breaker.<br /><br />Here\\'s the verdict: The R2s made me like earbuds again. I was considering the Shure SE215s, but these reign superior. Once they\\'re in my ears, I don\\'t feel like I need to take them out. They feel at home. Even Apple\\'s EarPods, which \\\\\\\\\"sit\\\\\\\\\" in my ears nicely, don\\'t make me forget that I\\'m listening to music through small pieces of plastic in my ears. The R2s do, and they don\\'t look ridiculous like some earbuds. My friend even told me he didn\\'t notice I was wearing them because they\\'re so small. That\\'s awesome.e the design, but there\\'s one ergonomic inconsistency: The aluminum box. It looks cool, and I can see why the designer would have put it there. However, if you want to use these as a versatile pair of IEMs, you may walk with them once in a while, or just move around a bit. The latter is inevitable, and when you do choose to move around you\\'ll hear some strange thudding sounds. That\\'s the box attempting to defy gravity. Every time I hear this I tell myself it\\'s cool to look at, but doesn\\'t need to be so heavy and certainly doesn\\'t add any special functionality. The heaviness, I suppose, adds value to the IEMs. I would just prefer it wasn\\'t here, especially when I\\'m using these to perform.<br /><br />While these are \\\\\\\\\"reference\\\\\\\\\" series -- at least according to the marketing by Flare -- I don\\'t recommend using them for referencing. The R2s don\\'t produce a completely flat sound like Sonys do. They\\'re amazing for listening to, but not necessarily for studio work. I tried mixing a few song using them just for fun, and I noticed that most of my mixes tended to lose the low-mid range on other speakers and headphones simply because the R2s are warm. This characteristic is great when listening to music, but not for mixing/producing it.<br /><br />If you\\'re a musician, you\\'ll find that these are great for monitoring (and thus they are named in-ear monitors). I used them to monitor my vocals and piano while recording an entire song and they worked great. The warmth helps make things less straining on the ears, and there\\'s not so much bass that I get a headache using them after a while. I also used these to monitor my synth and the rest of the band while playing live, and the foam tips isolated the sound very well.<br /><br />It\\'s worth noting that since these are in-ear monitors, there is no microphone. The aluminum block in the middle of the cable just acts as a splitter -- there\\'s no hidden microphone. At first this bugged me, because I would receive a call and forget I couldn\\'t use these headphones to talk. After a while, I just accepted it. There\\'s no reason for IEMs to have a microphone since there\\'s no way for you to use it as a talkback to your band or anything. It also goes against the way that Flare built these, which is to solely focus on recreating sound accurately, not adding more sound. Bottom line: A microphone would have been useful, but there isn\\'t one, and that shouldn\\'t be a deal breaker.<br /><br />Here\\'s the verdict: The R2s made me like earbuds again. I was considering the Shure SE215s, but these reign superior. Once they\\'re in my ears, I don\\'t feel like I need to take them out. They feel at home. Even Apple\\'s EarPods, which \\\\\\\\\"sit\\\\\\\\\" in my ears nicely, don\\'t make me forget that I\\'m listening to music through small pieces of plastic in my ears. The R2s do, and they don\\'t look ridiculous like some earbuds. My friend even told me he didn\\'t notice I was wearing them because they\\'re so small. That\\'s awesome.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reviews.loc[reviews['review_id'] == \"R2S8TX3KZU9TNW\"]['review_body'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dva",
   "language": "python",
   "name": "dva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
