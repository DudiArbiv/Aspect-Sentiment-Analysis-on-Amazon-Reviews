{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/apple/Documents/gatech/dva_6242/project/notebooks/data/raw/amazon_reviews_us_Electronics_v1_00.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-827c23964a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maspect_extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maspect_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maspect_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/gatech/dva_6242/project/src/models/aspect_extraction.py\u001b[0m in \u001b[0;36maspect_extraction\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBASE_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/data/raw/amazon_reviews_us_Electronics_v1_00.tsv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfetch_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0maspect_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_aspects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/gatech/dva_6242/project/src/models/aspect_extraction.py\u001b[0m in \u001b[0;36mfetch_reviews\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch_reviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dva/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/apple/Documents/gatech/dva_6242/project/notebooks/data/raw/amazon_reviews_us_Electronics_v1_00.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "    \n",
    "# from src.models import aspect_extraction\n",
    "\n",
    "# aspect_extraction.aspect_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get this from some place else. This is just for dummy usage\n",
    "stop_words=[\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \n",
    "            \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \n",
    "            \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "            \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \n",
    "            \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "            \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n",
    "            \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \n",
    "            \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "            \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_lg\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace                  object\n",
       "customer_id                   int64\n",
       "review_id                    object\n",
       "product_id                   object\n",
       "product_parent                int64\n",
       "product_title                object\n",
       "product_category             object\n",
       "star_rating                   int64\n",
       "helpful_votes                 int64\n",
       "total_votes                   int64\n",
       "vine                         object\n",
       "verified_purchase            object\n",
       "review_headline              object\n",
       "review_body                  object\n",
       "review_date          datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.path.abspath(os.path.join('..')) # base path of project\n",
    "\n",
    "file_path = BASE_PATH + '/data/raw/amazon_reviews_us_Electronics_v1_00.tsv'\n",
    "\n",
    "raw_data = pd.read_table(file_path,error_bad_lines=False, nrows=100)\n",
    "raw_data\n",
    "#review_body = raw_data['review_body']\n",
    "#reviews = raw_data[['review_id', 'review_body']]\n",
    "\n",
    "raw_data['review_date'] = pd.to_datetime(raw_data['review_date'])\n",
    "raw_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspects(x):\n",
    "    doc=nlp(x) \n",
    "    doc=[i.text for i in doc if i.text not in stop_words and i.pos_==\"NOUN\"] ## Remove common words and retain only nouns\n",
    "    doc=list(map(lambda i: i.lower(),doc)) ## Normalize text to lower case\n",
    "    doc=pd.Series(doc)\n",
    "    doc=doc.value_counts().head().index.tolist() ## Get 5 most frequent nouns\n",
    "    return doc\n",
    "\n",
    "aspects = []\n",
    "\n",
    "for review in review_body :\n",
    "    aspects.append(get_aspects(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DT det DET\n",
      "sound JJ amod ADJ\n",
      "quality NN nsubj NOUN\n",
      "of IN prep ADP\n",
      "the DT det DET\n",
      "speakers NNS pobj NOUN\n",
      "are VBP ROOT VERB\n",
      "wonderful JJ acomp ADJ\n",
      ". . punct PUNCT\n",
      "However RB advmod ADV\n",
      ", , punct PUNCT\n",
      "the DT det DET\n",
      "packaging NN nsubj NOUN\n",
      "could MD aux VERB\n",
      "have VB aux VERB\n",
      "been VBN ROOT VERB\n",
      "better JJR acomp ADJ\n",
      ". . punct PUNCT\n",
      "Photos NNS nsubj NOUN\n",
      "under IN prep ADP\n",
      "low JJ amod ADJ\n",
      "lighting NN pobj NOUN\n",
      "is VBZ ROOT VERB\n",
      "poor JJ amod ADJ\n",
      "- : punct PUNCT\n",
      "both DT preconj DET\n",
      "front NN amod NOUN\n",
      "and CC cc CCONJ\n",
      "back NN conj NOUN\n",
      "cameras NNS attr NOUN\n"
     ]
    }
   ],
   "source": [
    "dummy = \"The sound quality of the speakers are wonderful. However, the packaging could have been better. Photos under low lighting is poor - both front and back cameras\"\n",
    "doc=nlp(dummy) \n",
    "for token in doc:\n",
    "    print(token.text,token.tag_, token.dep_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sound quality  *** quality  *** nsubj  *** are\n",
      "the speakers  *** speakers  *** pobj  *** of\n",
      "the packaging  *** packaging  *** nsubj  *** been\n",
      "Photos  *** Photos  *** nsubj  *** is\n",
      "low lighting  *** lighting  *** pobj  *** under\n",
      "poor - both front and back cameras  *** cameras  *** attr  *** is\n"
     ]
    }
   ],
   "source": [
    "#noun chunks\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text,\" ***\", chunk.root.text, \" ***\",chunk.root.dep_,\" ***\", chunk.root.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **** det **** quality **** False NOUN []\n",
      "sound **** amod **** quality **** False NOUN []\n",
      "quality **** nsubj **** are **** False VERB [The, sound, of]\n",
      "of **** prep **** quality **** False NOUN [speakers]\n",
      "the **** det **** speakers **** False NOUN []\n",
      "speakers **** pobj **** of **** False ADP [the]\n",
      "are **** ROOT **** are **** False VERB [quality, wonderful, .]\n",
      "wonderful **** acomp **** are **** False VERB []\n",
      ". **** punct **** are **** False VERB []\n",
      "However **** advmod **** been **** False VERB []\n",
      ", **** punct **** been **** False VERB []\n",
      "the **** det **** packaging **** False NOUN []\n",
      "packaging **** nsubj **** been **** False VERB [the]\n",
      "could **** aux **** been **** False VERB []\n",
      "have **** aux **** been **** False VERB []\n",
      "been **** ROOT **** been **** False VERB [However, ,, packaging, could, have, better, .]\n",
      "better **** acomp **** been **** False VERB []\n",
      ". **** punct **** been **** False VERB []\n",
      "Photos **** nsubj **** is **** False VERB [under]\n",
      "under **** prep **** Photos **** False NOUN [lighting]\n",
      "low **** amod **** lighting **** False NOUN []\n",
      "lighting **** pobj **** under **** False ADP [low]\n",
      "is **** ROOT **** is **** False VERB [Photos, cameras]\n",
      "poor **** amod **** front **** False NOUN [-]\n",
      "- **** punct **** poor **** False ADJ []\n",
      "both **** preconj **** front **** False NOUN []\n",
      "front **** amod **** cameras **** False NOUN [poor, both, and, back]\n",
      "and **** cc **** front **** False NOUN []\n",
      "back **** conj **** front **** False NOUN []\n",
      "cameras **** attr **** is **** False VERB [front]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,\"****\" ,token.dep_, \"****\" ,token.head.text, \"****\" ,token.is_stop,token.head.pos_,\n",
    "          [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [11/Nov/2018 19:18:46] \"GET / HTTP/1.1\" 200 18731\n",
      "127.0.0.1 - - [11/Nov/2018 19:18:47] \"GET / HTTP/1.1\" 200 18731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this if you want to visualise dependancy tree\n",
    "spacy.displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Bass, lacking)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Zero RULE \n",
    "## Noun - Adjective pairs\n",
    "\n",
    "## Very basic rule. Should be least weightage\n",
    "\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','PROPN'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'ADJ':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'sound'),\n",
       " ('lighting', 'low'),\n",
       " ('front', 'poor'),\n",
       " ('cameras', 'front')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIRST RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "## RULE = M is child of A with a relationshio of amod\n",
    "\n",
    "rule1_pairs = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"amod\":\n",
    "        rule1_pairs.append((token.head.text, token.text))\n",
    "\n",
    "rule1_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SECOND RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Direct Object - A is a child of something with relationship of nsubj, while \n",
    "# M is a child of the same something with relationship of dobj\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule2_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "        if(child.dep_ == \"dobj\"):\n",
    "            M = child.text\n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule2_pairs.append((A, M))   \n",
    "    \n",
    "         \n",
    "            \n",
    "        \n",
    "        \n",
    "rule2_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'wonderful'), ('packaging', 'better'), ('Photos', 'better')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## THIRD RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adjectival Complement - A is a child of something with relationship of nsubj, while \n",
    "# M is a child of the same something with relationship of acomp\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule3_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    B = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"acomp\"):\n",
    "            M = child.text\n",
    "        \n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule3_pairs.append((A, M)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule3_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while \n",
    "# M is a child of the same something with relationship of advmod\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule4_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    M = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubjpass\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"advmod\"):\n",
    "            M = child.text\n",
    "        \n",
    "    if(A != \"999999\" and M != \"999999\"):\n",
    "        rule4_pairs.append((A, M)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule4_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Complement of a copular verb - A is a child of M with relationship of nsubj, while \n",
    "# M has a child with relationship of cop\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule5_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    buf_var = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"cop\"):\n",
    "            buf_var = child.text\n",
    "        \n",
    "    if(A != \"999999\" or buf_var != \"999999\"):\n",
    "        rule3_pairs.append((A, token.text)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule5_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'wonderful'), ('packaging', 'better'), ('Photos', 'better')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule3_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aspects = []\n",
    "aspects = rule1_pairs + rule2_pairs + rule3_pairs + rule4_pairs + rule5_pairs \n",
    "aspects\n",
    "\n",
    "review_id = \"guhjsus23\"\n",
    "\n",
    "{\"review_id\" : review_id, \"aspects\" : aspects }\n",
    "aspects = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_extraction(row,nlp):\n",
    "    review_body = row['review_body']\n",
    "    review_id = row['review_id']\n",
    "\n",
    "    doc=nlp(review_body)\n",
    "\n",
    "\n",
    "    ## FIRST RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## RULE = M is child of A with a relationshio of amod\n",
    "    rule1_pairs = []\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"amod\":\n",
    "            rule1_pairs.append((token.head.text, token.text))\n",
    "            #return row['height'] * row['width']\n",
    "\n",
    "\n",
    "    ## SECOND RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    #Direct Object - A is a child of something with relationship of nsubj, while\n",
    "    # M is a child of the same something with relationship of dobj\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule2_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\"):\n",
    "                A = child.text\n",
    "            if(child.dep_ == \"dobj\"):\n",
    "                M = child.text\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule2_pairs.append((A, M))\n",
    "\n",
    "\n",
    "    ## THIRD RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    #Adjectival Complement - A is a child of something with relationship of nsubj, while\n",
    "    # M is a child of the same something with relationship of acomp\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule3_pairs = []\n",
    "\n",
    "    for token in doc:\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\"):\n",
    "                A = child.text\n",
    "\n",
    "            if(child.dep_ == \"acomp\"):\n",
    "                M = child.text\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule3_pairs.append((A, M))\n",
    "\n",
    "    ## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "    #Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while\n",
    "    # M is a child of the same something with relationship of advmod\n",
    "\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule4_pairs = []\n",
    "    for token in doc:\n",
    "\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubjpass\"):\n",
    "                A = child.text\n",
    "\n",
    "            if(child.dep_ == \"advmod\"):\n",
    "                M = child.text\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule4_pairs.append((A, M))\n",
    "\n",
    "\n",
    "    ## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "    #Complement of a copular verb - A is a child of M with relationship of nsubj, while\n",
    "    # M has a child with relationship of cop\n",
    "\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule5_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        buf_var = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\"):\n",
    "                A = child.text\n",
    "\n",
    "            if(child.dep_ == \"cop\"):\n",
    "                buf_var = child.text\n",
    "\n",
    "        if(A != \"999999\" and buf_var != \"999999\"):\n",
    "            rule3_pairs.append((A, token.text))\n",
    "\n",
    "    aspects = []\n",
    "    aspects = rule1_pairs + rule2_pairs + rule3_pairs +rule4_pairs +rule5_pairs\n",
    "    dic = {\"review_id\" : review_id , \"aspect_pairs\" : aspects}\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_id': 'R372S58V6D11AT', 'aspect_pairs': [('Bass', 'lacking')]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_lg\")\n",
    "reviews.apply(lambda row: apply_extraction(row,nlp), axis=1)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[[VIDEOID:ca7421903fd1ad5c64ae1dc42a160649]] Earbuds have always been an issue for me. Mine is one of those stereotypical stories -- I can\\'t find a pair that fits my ears well. I\\'ve tried so many types of earbuds and most of them give my ear canals some sort of fatigue. It\\'s not that they sound bad, just that keeping them in my ears for more than 10 minutes is painful. The only ones I could tolerate were the Apple EarPods, and I have a love/hate relationship with them. Sure, they sit nicely in my ears, but them being fully open means I lose my music to the crickets of night and pelicans of day. Well, no more! I found the Flare R2A in-ear monitors, and seems my fear of earbuds is over.<br /><br />Disclaimer: This product was provided at a discounted price in exchange for an honest review.<br /><br />The R2s began their life on Kickstarter with a campaign that raised over $170,000. That\\'s quite a lot for IEMs, which are a rather niche market. Flare is a British company that strives for excellence in sound, and hopes that the world can join them in this pursuit. Before the R2s, the company made loudspeakers, so in-ears is a bit of a different industry. I think they did a fine job of things.<br /><br />I listen to a lot of different genres of music, but mostly folk and dream pop lately. To test out the R2s, I listened to hip-hop, jazz, EDM, instrumental guitar and piano, rock, classical, and of course the aforementioned folk. They performed consistently well in every genre. They also look great.<br /><br />First, of course, the sound. These IEMs aren\\'t active noise canceling or anything fancy, which is good because noise canceling often diminishes the sound quality. The R2s are still great for keeping outside noises to a minimum. They use the same plushy foam tips as earplugs, which makes for a comfortable and quiet listening environment. I tried them at work, in the bus, walking down a busy road, and even in a studio while recording. There\\'s absolutely no sound leakage at all, which is great for quiet environments, and none of the quality seems to be lost when the environment is noisy.<br /><br />People sometimes rant about flat response and how it\\'s better than everything else. Those people might be troubled by the R2s. They\\'re warmer than most earbuds, but don\\'t have muddy bass. The main issue with earbuds is always treble: there\\'s way too much of it everywhere. Then Skullcandy wanted to have fun so they started adding a bunch of bass to the mix. Everything above 80Hz seemed to have been lost. The R2s have none of those problems -- highs are crisp, mids cut through well, and the lows of course deliver the much-needed punch, rather than a drone. The responsiveness of everything is very tight.<br /><br />As I said before, everything I listened to with these IEMs sounded wonderful. They revealed details in songs that I didn\\'t know were there, while also being comfortable, affordable, and easy to use. The highs were not overbearing, but pronounced; the high-mids don\\'t clutter the highs at all; the low-mids keep all the bass lines in check; and the lows make sure you remember that the bass drum exists without making you forget about the guitars in the mid-range. That\\'s a great achievement. I really love the way these sound. Everything is balanced. Overall, it\\'s a bit warm, but I would much rather it be warm than sound like tinny old Apple earbuds from the early 2000s, with their mesh and bass-less muddle.<br /><br />On to the design. These things are beautifully minimal, but aren\\'t trying to be artistic, which is nice for a change. The earbuds themselves are black (or whatever color you chose), and the tips and cable match that. There\\'s also a rectangular machined aluminum box that splits the stereo signal for the left and right channels. It doesn\\'t need to be as big as it is, but it does add some pizzazz to things. Lastly, there\\'s the 3.5mm connector, which on mine is black with two gold stripes running through it.<br /><br />I love the design, but there\\'s one ergonomic inconsistency: The aluminum box. It looks cool, and I can see why the designer would have put it there. However, if you want to use these as a versatile pair of IEMs, you may walk with them once in a while, or just move around a bit. The latter is inevitable, and when you do choose to move around you\\'ll hear some strange thudding sounds. That\\'s the box attempting to defy gravity. Every time I hear this I tell myself it\\'s cool to look at, but doesn\\'t need to be so heavy and certainly doesn\\'t add any special functionality. The heaviness, I suppose, adds value to the IEMs. I would just prefer it wasn\\'t here, especially when I\\'m using these to perform.<br /><br />While these are \\\\\\\\\"reference\\\\\\\\\" series -- at least according to the marketing by Flare -- I don\\'t recommend using them for referencing. The R2s don\\'t produce a completely flat sound like Sonys do. They\\'re amazing for listening to, but not necessarily for studio work. I tried mixing a few song using them just for fun, and I noticed that most of my mixes tended to lose the low-mid range on other speakers and headphones simply because the R2s are warm. This characteristic is great when listening to music, but not for mixing/producing it.<br /><br />If you\\'re a musician, you\\'ll find that these are great for monitoring (and thus they are named in-ear monitors). I used them to monitor my vocals and piano while recording an entire song and they worked great. The warmth helps make things less straining on the ears, and there\\'s not so much bass that I get a headache using them after a while. I also used these to monitor my synth and the rest of the band while playing live, and the foam tips isolated the sound very well.<br /><br />It\\'s worth noting that since these are in-ear monitors, there is no microphone. The aluminum block in the middle of the cable just acts as a splitter -- there\\'s no hidden microphone. At first this bugged me, because I would receive a call and forget I couldn\\'t use these headphones to talk. After a while, I just accepted it. There\\'s no reason for IEMs to have a microphone since there\\'s no way for you to use it as a talkback to your band or anything. It also goes against the way that Flare built these, which is to solely focus on recreating sound accurately, not adding more sound. Bottom line: A microphone would have been useful, but there isn\\'t one, and that shouldn\\'t be a deal breaker.<br /><br />Here\\'s the verdict: The R2s made me like earbuds again. I was considering the Shure SE215s, but these reign superior. Once they\\'re in my ears, I don\\'t feel like I need to take them out. They feel at home. Even Apple\\'s EarPods, which \\\\\\\\\"sit\\\\\\\\\" in my ears nicely, don\\'t make me forget that I\\'m listening to music through small pieces of plastic in my ears. The R2s do, and they don\\'t look ridiculous like some earbuds. My friend even told me he didn\\'t notice I was wearing them because they\\'re so small. That\\'s awesome.e the design, but there\\'s one ergonomic inconsistency: The aluminum box. It looks cool, and I can see why the designer would have put it there. However, if you want to use these as a versatile pair of IEMs, you may walk with them once in a while, or just move around a bit. The latter is inevitable, and when you do choose to move around you\\'ll hear some strange thudding sounds. That\\'s the box attempting to defy gravity. Every time I hear this I tell myself it\\'s cool to look at, but doesn\\'t need to be so heavy and certainly doesn\\'t add any special functionality. The heaviness, I suppose, adds value to the IEMs. I would just prefer it wasn\\'t here, especially when I\\'m using these to perform.<br /><br />While these are \\\\\\\\\"reference\\\\\\\\\" series -- at least according to the marketing by Flare -- I don\\'t recommend using them for referencing. The R2s don\\'t produce a completely flat sound like Sonys do. They\\'re amazing for listening to, but not necessarily for studio work. I tried mixing a few song using them just for fun, and I noticed that most of my mixes tended to lose the low-mid range on other speakers and headphones simply because the R2s are warm. This characteristic is great when listening to music, but not for mixing/producing it.<br /><br />If you\\'re a musician, you\\'ll find that these are great for monitoring (and thus they are named in-ear monitors). I used them to monitor my vocals and piano while recording an entire song and they worked great. The warmth helps make things less straining on the ears, and there\\'s not so much bass that I get a headache using them after a while. I also used these to monitor my synth and the rest of the band while playing live, and the foam tips isolated the sound very well.<br /><br />It\\'s worth noting that since these are in-ear monitors, there is no microphone. The aluminum block in the middle of the cable just acts as a splitter -- there\\'s no hidden microphone. At first this bugged me, because I would receive a call and forget I couldn\\'t use these headphones to talk. After a while, I just accepted it. There\\'s no reason for IEMs to have a microphone since there\\'s no way for you to use it as a talkback to your band or anything. It also goes against the way that Flare built these, which is to solely focus on recreating sound accurately, not adding more sound. Bottom line: A microphone would have been useful, but there isn\\'t one, and that shouldn\\'t be a deal breaker.<br /><br />Here\\'s the verdict: The R2s made me like earbuds again. I was considering the Shure SE215s, but these reign superior. Once they\\'re in my ears, I don\\'t feel like I need to take them out. They feel at home. Even Apple\\'s EarPods, which \\\\\\\\\"sit\\\\\\\\\" in my ears nicely, don\\'t make me forget that I\\'m listening to music through small pieces of plastic in my ears. The R2s do, and they don\\'t look ridiculous like some earbuds. My friend even told me he didn\\'t notice I was wearing them because they\\'re so small. That\\'s awesome.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reviews.loc[reviews['review_id'] == \"R2S8TX3KZU9TNW\"]['review_body'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dva",
   "language": "python",
   "name": "dva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
