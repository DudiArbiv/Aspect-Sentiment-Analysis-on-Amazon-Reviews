{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get this from some place else. This is just for dummy usage\n",
    "stop_words=[\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \n",
    "            \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \n",
    "            \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "            \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \n",
    "            \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "            \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n",
    "            \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \n",
    "            \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "            \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_lg\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.abspath(os.path.join('..')) # base path of project\n",
    "\n",
    "file_path = BASE_PATH + '/data/raw/amazon_reviews_us_Electronics_v1_00.tsv'\n",
    "\n",
    "raw_data = pd.read_table(file_path,error_bad_lines=False, nrows=100)\n",
    "\n",
    "review_body = raw_data['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspects(x):\n",
    "    doc=nlp(x) \n",
    "    doc=[i.text for i in doc if i.text not in stop_words and i.pos_==\"NOUN\"] ## Remove common words and retain only nouns\n",
    "    doc=list(map(lambda i: i.lower(),doc)) ## Normalize text to lower case\n",
    "    doc=pd.Series(doc)\n",
    "    doc=doc.value_counts().head().index.tolist() ## Get 5 most frequent nouns\n",
    "    return doc\n",
    "\n",
    "aspects = []\n",
    "\n",
    "for review in review_body :\n",
    "    aspects.append(get_aspects(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DT det DET\n",
      "sound JJ amod ADJ\n",
      "quality NN nsubj NOUN\n",
      "of IN prep ADP\n",
      "the DT det DET\n",
      "speakers NNS pobj NOUN\n",
      "are VBP ROOT VERB\n",
      "wonderful JJ acomp ADJ\n",
      ". . punct PUNCT\n",
      "However RB advmod ADV\n",
      ", , punct PUNCT\n",
      "the DT det DET\n",
      "packaging NN nsubj NOUN\n",
      "could MD aux VERB\n",
      "have VB aux VERB\n",
      "been VBN ROOT VERB\n",
      "better JJR acomp ADJ\n",
      ". . punct PUNCT\n",
      "Photos NNS nsubj NOUN\n",
      "under IN prep ADP\n",
      "low JJ amod ADJ\n",
      "lighting NN pobj NOUN\n",
      "is VBZ ROOT VERB\n",
      "poor JJ amod ADJ\n",
      "- : punct PUNCT\n",
      "both DT preconj DET\n",
      "front NN amod NOUN\n",
      "and CC cc CCONJ\n",
      "back NN conj NOUN\n",
      "cameras NNS attr NOUN\n"
     ]
    }
   ],
   "source": [
    "dummy = \"The sound quality of the speakers are wonderful. However, the packaging could have been better. Photos under low lighting is poor - both front and back cameras\"\n",
    "doc=nlp(dummy) \n",
    "for token in doc:\n",
    "    print(token.text,token.tag_, token.dep_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sound quality  *** quality  *** nsubj  *** are\n",
      "the speakers  *** speakers  *** pobj  *** of\n",
      "the packaging  *** packaging  *** nsubj  *** been\n",
      "Photos  *** Photos  *** nsubj  *** is\n",
      "low lighting  *** lighting  *** pobj  *** under\n",
      "poor - both front and back cameras  *** cameras  *** attr  *** is\n"
     ]
    }
   ],
   "source": [
    "#noun chunks\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text,\" ***\", chunk.root.text, \" ***\",chunk.root.dep_,\" ***\", chunk.root.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The **** det **** quality **** NOUN []\n",
      "sound **** amod **** quality **** NOUN []\n",
      "quality **** nsubj **** are **** VERB [The, sound, of]\n",
      "of **** prep **** quality **** NOUN [speakers]\n",
      "the **** det **** speakers **** NOUN []\n",
      "speakers **** pobj **** of **** ADP [the]\n",
      "are **** ROOT **** are **** VERB [quality, wonderful, .]\n",
      "wonderful **** acomp **** are **** VERB []\n",
      ". **** punct **** are **** VERB []\n",
      "However **** advmod **** been **** VERB []\n",
      ", **** punct **** been **** VERB []\n",
      "the **** det **** packaging **** NOUN []\n",
      "packaging **** nsubj **** been **** VERB [the]\n",
      "could **** aux **** been **** VERB []\n",
      "have **** aux **** been **** VERB []\n",
      "been **** ROOT **** been **** VERB [However, ,, packaging, could, have, better, .]\n",
      "better **** acomp **** been **** VERB []\n",
      ". **** punct **** been **** VERB []\n",
      "Photos **** nsubj **** is **** VERB [under]\n",
      "under **** prep **** Photos **** NOUN [lighting]\n",
      "low **** amod **** lighting **** NOUN []\n",
      "lighting **** pobj **** under **** ADP [low]\n",
      "is **** ROOT **** is **** VERB [Photos, cameras]\n",
      "poor **** amod **** front **** NOUN [-]\n",
      "- **** punct **** poor **** ADJ []\n",
      "both **** preconj **** front **** NOUN []\n",
      "front **** amod **** cameras **** NOUN [poor, both, and, back]\n",
      "and **** cc **** front **** NOUN []\n",
      "back **** conj **** front **** NOUN []\n",
      "cameras **** attr **** is **** VERB [front]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,\"****\" ,token.dep_, \"****\" ,token.head.text, \"****\" ,token.is_stop,token.head.pos_,\n",
    "          [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Nov/2018 14:12:52] \"GET / HTTP/1.1\" 200 18731\n",
      "127.0.0.1 - - [06/Nov/2018 14:12:53] \"GET /favicon.ico HTTP/1.1\" 200 18731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Shutting down server on port 5000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this if you want to visualise dependancy tree\n",
    "#spacy.displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(quality, wonderful),\n",
       " (speakers, wonderful),\n",
       " (packaging, better),\n",
       " (Photos, low),\n",
       " (lighting, poor)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Zero RULE \n",
    "## Noun - Adjective pairs\n",
    "\n",
    "## Very basic rule. Should be least weightage\n",
    "\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','PROPN'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'ADJ':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'sound'),\n",
       " ('lighting', 'low'),\n",
       " ('front', 'poor'),\n",
       " ('cameras', 'front')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIRST RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "## RULE = M is child of A with a relationshio of amod\n",
    "\n",
    "rule1_pairs = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"amod\":\n",
    "        rule1_pairs.append((token.head.text, token.text))\n",
    "\n",
    "rule1_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SECOND RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Direct Object - A is a child of something with relationship of nsubj, while \n",
    "# M is a child of the same something with relationship of dobj\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule2_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    B = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "        if(child.dep_ == \"dobj\"):\n",
    "            M = child.text\n",
    "    if(A != \"999999\" and B != \"999999\"):\n",
    "        rule2_pairs.append((A, M))   \n",
    "    \n",
    "         \n",
    "            \n",
    "        \n",
    "        \n",
    "rule2_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quality', 'wonderful'), ('packaging', 'better'), ('Photos', 'better')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## THIRD RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adjectival Complement - A is a child of something with relationship of nsubj, while \n",
    "# M is a child of the same something with relationship of acomp\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule3_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    B = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"acomp\"):\n",
    "            M = child.text\n",
    "        \n",
    "    if(A != \"999999\" or B != \"999999\"):\n",
    "        rule3_pairs.append((A, M)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule3_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while \n",
    "# M is a child of the same something with relationship of advmod\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule4_pairs = []\n",
    "for token in doc:\n",
    "\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    B = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubjpass\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"advmod\"):\n",
    "            M = child.text\n",
    "        \n",
    "    if(A != \"999999\" or B != \"999999\"):\n",
    "        rule4_pairs.append((A, M)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule4_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "#Complement of a copular verb - A is a child of M with relationship of nsubj, while \n",
    "# M has a child with relationship of cop\n",
    "\n",
    "#Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "rule5_pairs = []\n",
    "for token in doc:\n",
    "    children = token.children\n",
    "    A = \"999999\"\n",
    "    buf_var = \"999999\"\n",
    "    for child in children :\n",
    "        if(child.dep_ == \"nsubj\"):\n",
    "            A = child.text\n",
    "          \n",
    "        if(child.dep_ == \"cop\"):\n",
    "            buf_var = child.text\n",
    "        \n",
    "    if(A != \"999999\" or buf_var != \"999999\"):\n",
    "        rule3_pairs.append((A, token.text)) \n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "rule5_pairs        \n",
    "        \n",
    "        \n",
    "   # if token.dep_ == \"amod\":\n",
    "   #     rule1_pairs.append((token.head.text, token.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dva",
   "language": "python",
   "name": "dva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
